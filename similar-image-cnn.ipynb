{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thank you TAREK HAMDI https://www.kaggle.com/code/hamditarek/similar-image-cnn-cosine-similarity\n",
    "this is amazing notebook and thank you for your knowledge sharing! I will inspire to do the same and contribute to the community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:08:59.198366Z",
     "iopub.status.busy": "2022-06-11T00:08:59.197777Z",
     "iopub.status.idle": "2022-06-11T00:09:04.987512Z",
     "shell.execute_reply": "2022-06-11T00:09:04.986667Z",
     "shell.execute_reply.started": "2022-06-11T00:08:59.198323Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.applications.xception import Xception,preprocess_input\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input\n",
    "from keras.backend import reshape\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading and Preprocessing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\19095\\\\Documents\\\\Capstone\\\\CapstoneH-M'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T23:55:38.04825Z",
     "iopub.status.busy": "2022-06-10T23:55:38.047975Z",
     "iopub.status.idle": "2022-06-10T23:55:38.054999Z",
     "shell.execute_reply": "2022-06-10T23:55:38.054249Z",
     "shell.execute_reply.started": "2022-06-10T23:55:38.048212Z"
    }
   },
   "outputs": [],
   "source": [
    "# images_dir = '../input/h-and-m-personalized-fashion-recommendations/images'\n",
    "images_dir = 'C:\\\\Users\\\\19095\\\\Documents\\\\Capstone\\\\Dataset\\\\HandM\\\\images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T23:55:46.617101Z",
     "iopub.status.busy": "2022-06-10T23:55:46.616582Z",
     "iopub.status.idle": "2022-06-10T23:56:19.340843Z",
     "shell.execute_reply": "2022-06-10T23:56:19.340017Z",
     "shell.execute_reply.started": "2022-06-10T23:55:46.617058Z"
    }
   },
   "outputs": [],
   "source": [
    "images_path = getImagePaths(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T23:56:19.34308Z",
     "iopub.status.busy": "2022-06-10T23:56:19.342811Z",
     "iopub.status.idle": "2022-06-10T23:56:19.349849Z",
     "shell.execute_reply": "2022-06-10T23:56:19.349141Z",
     "shell.execute_reply.started": "2022-06-10T23:56:19.343045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T23:56:32.394422Z",
     "iopub.status.busy": "2022-06-10T23:56:32.393617Z",
     "iopub.status.idle": "2022-06-10T23:56:32.398271Z",
     "shell.execute_reply": "2022-06-10T23:56:32.397578Z",
     "shell.execute_reply.started": "2022-06-10T23:56:32.394383Z"
    }
   },
   "outputs": [],
   "source": [
    "X = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T23:56:44.732871Z",
     "iopub.status.busy": "2022-06-10T23:56:44.732597Z",
     "iopub.status.idle": "2022-06-11T00:00:51.781733Z",
     "shell.execute_reply": "2022-06-11T00:00:51.780808Z",
     "shell.execute_reply.started": "2022-06-10T23:56:44.732841Z"
    }
   },
   "outputs": [],
   "source": [
    "for path in images_path[:8000]:\n",
    "    X.append(preprocess_img(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:00:51.784224Z",
     "iopub.status.busy": "2022-06-11T00:00:51.783917Z",
     "iopub.status.idle": "2022-06-11T00:00:53.283104Z",
     "shell.execute_reply": "2022-06-11T00:00:53.282309Z",
     "shell.execute_reply.started": "2022-06-11T00:00:51.784184Z"
    }
   },
   "outputs": [],
   "source": [
    "# each X pixels should be scaled \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:00:53.284668Z",
     "iopub.status.busy": "2022-06-11T00:00:53.284391Z",
     "iopub.status.idle": "2022-06-11T00:00:53.292258Z",
     "shell.execute_reply": "2022-06-11T00:00:53.291367Z",
     "shell.execute_reply.started": "2022-06-11T00:00:53.284632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 225, 225, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:08:07.580681Z",
     "iopub.status.busy": "2022-06-11T00:08:07.580388Z",
     "iopub.status.idle": "2022-06-11T00:08:07.594116Z",
     "shell.execute_reply": "2022-06-11T00:08:07.593163Z",
     "shell.execute_reply.started": "2022-06-11T00:08:07.580648Z"
    }
   },
   "outputs": [],
   "source": [
    "string_article_id = []\n",
    "\n",
    "for path in images_path[:8000]:\n",
    "#     string_article_id.append(int(path.split('/')[5][:10]))\n",
    "    string_article_id.append(int(path.split('\\\\')[9][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:08:08.688489Z",
     "iopub.status.busy": "2022-06-11T00:08:08.687688Z",
     "iopub.status.idle": "2022-06-11T00:08:09.200645Z",
     "shell.execute_reply": "2022-06-11T00:08:09.199878Z",
     "shell.execute_reply.started": "2022-06-11T00:08:08.688443Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "articles = pd.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/articles.csv\")\n",
    "cols = ['article_id','product_group_name']\n",
    "temp = articles[cols]\n",
    "\n",
    "label = pd.DataFrame(string_article_id, columns=['article_id'])\n",
    "label = label.merge(temp, how = 'left', left_on='article_id',right_on='article_id')\n",
    "\n",
    "\n",
    "label['product_group_name_coded'] = le.fit_transform(label['product_group_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:08:11.129278Z",
     "iopub.status.busy": "2022-06-11T00:08:11.129006Z",
     "iopub.status.idle": "2022-06-11T00:08:11.134591Z",
     "shell.execute_reply": "2022-06-11T00:08:11.133528Z",
     "shell.execute_reply.started": "2022-06-11T00:08:11.129248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_article_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:08:12.103895Z",
     "iopub.status.busy": "2022-06-11T00:08:12.103112Z",
     "iopub.status.idle": "2022-06-11T00:08:12.109992Z",
     "shell.execute_reply": "2022-06-11T00:08:12.109153Z",
     "shell.execute_reply.started": "2022-06-11T00:08:12.103845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:08:14.039818Z",
     "iopub.status.busy": "2022-06-11T00:08:14.039238Z",
     "iopub.status.idle": "2022-06-11T00:08:14.046284Z",
     "shell.execute_reply": "2022-06-11T00:08:14.045506Z",
     "shell.execute_reply.started": "2022-06-11T00:08:14.039779Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:08:17.506668Z",
     "iopub.status.busy": "2022-06-11T00:08:17.506096Z",
     "iopub.status.idle": "2022-06-11T00:08:20.071397Z",
     "shell.execute_reply": "2022-06-11T00:08:20.070585Z",
     "shell.execute_reply.started": "2022-06-11T00:08:17.50663Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = label['product_group_name_coded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:09:06.67134Z",
     "iopub.status.busy": "2022-06-11T00:09:06.670481Z"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(225, 225, 3)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(19)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:08:53.831175Z",
     "iopub.status.busy": "2022-06-11T00:08:53.830332Z",
     "iopub.status.idle": "2022-06-11T00:08:53.848631Z",
     "shell.execute_reply": "2022-06-11T00:08:53.847601Z",
     "shell.execute_reply.started": "2022-06-11T00:08:53.831128Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T00:08:48.864587Z",
     "iopub.status.busy": "2022-06-11T00:08:48.864093Z",
     "iopub.status.idle": "2022-06-11T00:08:48.878051Z",
     "shell.execute_reply": "2022-06-11T00:08:48.876939Z",
     "shell.execute_reply.started": "2022-06-11T00:08:48.864529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "168/168 [==============================] - 9s 52ms/step - loss: 18.3557 - accuracy: 0.4084\n",
      "Epoch 2/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 4.2125 - accuracy: 0.3933\n",
      "Epoch 3/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 3.6936 - accuracy: 0.4916\n",
      "Epoch 4/30\n",
      "168/168 [==============================] - 9s 56ms/step - loss: 3.7643 - accuracy: 0.5075\n",
      "Epoch 5/30\n",
      "168/168 [==============================] - 9s 55ms/step - loss: 3.4808 - accuracy: 0.4815\n",
      "Epoch 6/30\n",
      "168/168 [==============================] - 9s 54ms/step - loss: 2.5781 - accuracy: 0.5052\n",
      "Epoch 7/30\n",
      "168/168 [==============================] - 9s 54ms/step - loss: 2.6295 - accuracy: 0.5200\n",
      "Epoch 8/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 3.4565 - accuracy: 0.5235\n",
      "Epoch 9/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 2.1781 - accuracy: 0.5410\n",
      "Epoch 10/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 2.3768 - accuracy: 0.5493\n",
      "Epoch 11/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 2.4217 - accuracy: 0.5496\n",
      "Epoch 12/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 3.0401 - accuracy: 0.5315\n",
      "Epoch 13/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 1.7651 - accuracy: 0.5399\n",
      "Epoch 14/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 2.7381 - accuracy: 0.5392\n",
      "Epoch 15/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 1.9158 - accuracy: 0.5470\n",
      "Epoch 16/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 1.6366 - accuracy: 0.5455\n",
      "Epoch 17/30\n",
      "168/168 [==============================] - 9s 54ms/step - loss: 2.2615 - accuracy: 0.5558\n",
      "Epoch 18/30\n",
      "168/168 [==============================] - 9s 54ms/step - loss: 2.7634 - accuracy: 0.5433\n",
      "Epoch 19/30\n",
      "168/168 [==============================] - 9s 54ms/step - loss: 2.0101 - accuracy: 0.5636\n",
      "Epoch 20/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 1.7003 - accuracy: 0.5649\n",
      "Epoch 21/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 1.9171 - accuracy: 0.5700\n",
      "Epoch 22/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 2.0350 - accuracy: 0.5646\n",
      "Epoch 23/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 2.2561 - accuracy: 0.5435\n",
      "Epoch 24/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 1.4431 - accuracy: 0.5569\n",
      "Epoch 25/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 2.9922 - accuracy: 0.5625\n",
      "Epoch 26/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 1.8554 - accuracy: 0.5647\n",
      "Epoch 27/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 2.9899 - accuracy: 0.5599\n",
      "Epoch 28/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 1.4016 - accuracy: 0.5701\n",
      "Epoch 29/30\n",
      "168/168 [==============================] - 9s 53ms/step - loss: 1.7595 - accuracy: 0.5599\n",
      "Epoch 30/30\n",
      "168/168 [==============================] - 9s 52ms/step - loss: 3.6287 - accuracy: 0.5618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eb5c38c130>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 - 3s - loss: 5.5405 - accuracy: 0.5364 - 3s/epoch - 31ms/step\n",
      "\n",
      "Test accuracy: 0.5363636612892151\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 225, 225, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(X_test[0],axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  24.819036, -314.50995 ,   23.735468,   62.529076,   16.321854,\n",
       "         -25.804443,   49.197674,  -32.20737 ,   51.375164,   50.49598 ,\n",
       "          48.388817,  -47.81683 ,  -39.936295, -467.46664 ,  -97.01742 ,\n",
       "        -133.55089 , -437.42303 , -320.12933 , -113.06713 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(X_test[0],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(np.expand_dims(X_test[0],axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T23:55:43.807301Z",
     "iopub.status.busy": "2022-06-10T23:55:43.806463Z",
     "iopub.status.idle": "2022-06-10T23:55:43.819733Z",
     "shell.execute_reply": "2022-06-10T23:55:43.818836Z",
     "shell.execute_reply.started": "2022-06-10T23:55:43.80725Z"
    }
   },
   "outputs": [],
   "source": [
    "def getImagePaths(path):\n",
    "    \"\"\"\n",
    "    Function to Combine Directory Path with individual Image Paths\n",
    "    \n",
    "    parameters: path(string) - Path of directory\n",
    "    returns: image_names(string) - Full Image Path\n",
    "    \"\"\"\n",
    "    image_names = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            fullpath = os.path.join(dirname, filename)\n",
    "            image_names.append(fullpath)\n",
    "    return image_names\n",
    "\n",
    "def preprocess_img(img_path):\n",
    "    dsize = (225,225)\n",
    "    new_image=cv2.imread(img_path)\n",
    "    new_image=cv2.resize(new_image,dsize,interpolation=cv2.INTER_NEAREST)  \n",
    "    \n",
    "    # Add the image to a batch where it's the only member.\n",
    "#     new_image=np.expand_dims(new_image,axis=0)\n",
    "    \n",
    "    # preprocess_input on your inputs before passing them to the model. xception.preprocess_input will scale input pixels between -1 and 1.\n",
    "    new_image=preprocess_input(new_image)\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "def load_data():\n",
    "    # return 10000 images\n",
    "    output=[]\n",
    "    output=getImagePaths(images_dir)[:10000]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Defining model and extracting feature for all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T22:55:21.07525Z",
     "iopub.status.busy": "2022-06-10T22:55:21.074657Z",
     "iopub.status.idle": "2022-06-10T22:55:21.081257Z",
     "shell.execute_reply": "2022-06-10T22:55:21.080162Z",
     "shell.execute_reply.started": "2022-06-10T22:55:21.075213Z"
    }
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "#     model=Xception(weights='imagenet',include_top=False)\n",
    "#     for layer in model.layers:\n",
    "#         layer.trainable=False\n",
    "#         #model.summary()\n",
    "#     return model\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(225, 225, 3)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "def feature_extraction(image_data,model):\n",
    "    features=model.predict(image_data)\n",
    "    features=np.array(features)\n",
    "    features=features.flatten()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Finding the similar image through LSH and cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T20:52:18.932465Z",
     "iopub.status.busy": "2022-06-10T20:52:18.931758Z",
     "iopub.status.idle": "2022-06-10T20:52:18.936943Z",
     "shell.execute_reply": "2022-06-10T20:52:18.936271Z",
     "shell.execute_reply.started": "2022-06-10T20:52:18.932426Z"
    }
   },
   "outputs": [],
   "source": [
    "def result_vector_cosine(model,feature_vector,new_img):\n",
    "    new_feature = model.predict(new_img)\n",
    "    new_feature = np.array(new_feature)\n",
    "    new_feature = new_feature.flatten()\n",
    "    N_result = 12\n",
    "    nbrs = NearestNeighbors(n_neighbors=N_result, metric=\"cosine\").fit(feature_vector)\n",
    "    distances, indices = nbrs.kneighbors([new_feature])\n",
    "    return(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model=model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Result\n",
    "## Vector Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T20:52:23.783638Z",
     "iopub.status.busy": "2022-06-10T20:52:23.783102Z",
     "iopub.status.idle": "2022-06-10T20:55:39.243221Z",
     "shell.execute_reply": "2022-06-10T20:55:39.241961Z",
     "shell.execute_reply.started": "2022-06-10T20:52:23.7836Z"
    }
   },
   "outputs": [],
   "source": [
    "def input_show(data):\n",
    "    plt.title(\"Query Image\")\n",
    "    plt.imshow(data)\n",
    "  \n",
    "def show_result(data,result):\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    for i in range(0,12):\n",
    "        index_result=result[0][i]\n",
    "        plt.subplot(3,4,i+1)\n",
    "        plt.imshow(cv2.imread(data[index_result]))\n",
    "    plt.show()\n",
    "\n",
    "def main():  \n",
    "    features=[]\n",
    "    output=load_data()\n",
    "    main_model=model()\n",
    "    #Limiting the data for training\n",
    "    for i in output[:999]:\n",
    "        new_img=preprocess_img(i)\n",
    "        features.append(feature_extraction(new_img,main_model))\n",
    "    feature_vec = np.array(features)\n",
    "    result=result_vector_cosine(main_model,feature_vec,preprocess_img(output[1000]))\n",
    "    input_show(cv2.imread(output[1000]))\n",
    "    show_result(output,result)\n",
    "  \n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T20:55:39.245062Z",
     "iopub.status.busy": "2022-06-10T20:55:39.244817Z",
     "iopub.status.idle": "2022-06-10T20:57:12.860763Z",
     "shell.execute_reply": "2022-06-10T20:57:12.85835Z",
     "shell.execute_reply.started": "2022-06-10T20:55:39.245022Z"
    }
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
